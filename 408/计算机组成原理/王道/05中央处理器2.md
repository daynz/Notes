# 中央处理器

现代计算机中都配有完善的异常和中断处理系统，CPU的数据通路中有相应的异常检测和响应逻辑，外设接口中有相应的中断请求和控制逻辑，操作系统中有相应的中断服务程序。这些中断硬件电路和中断服务程序有机结合，共同完成异常和中断的处理过程。

### 异常和中断的基本概念
- **异常**：由CPU内部产生的意外事件，也称内中断。是CPU执行一条指令时，在其内部检测到的、与正在执行的指令相关的同步事件。
- **中断**：由来自CPU外部的设备向CPU发出的中断请求，也称外中断。是一种典型的由外部设备触发的、与当前正在执行的指令无关的异步事件。

异常和中断处理过程：若CPU在执行用户程序的第$i$条指令时检测到一个异常事件，或者执行第$i$条指令后发现一个中断请求信号，则CPU打断当前程序，转去执行相应的异常或中断处理程序。若能解决问题，在异常或中断处理程序的最后，CPU通过执行异常或中断返回指令，回到被打断的用户程序的第$i$条指令或第$i + 1$条指令继续执行；若发现是不可恢复的致命错误，则终止用户程序。通常由操作系统（和驱动程序）完成具体处理过程。异常和中断的处理过程基本相同，这也是有些教材将两者统称为中断的原因。

### 异常和中断的分类
#### 异常的分类
异常是由CPU内部产生的意外事件，分为**硬故障中断**和**程序性异常**。
- **硬故障中断**：由硬连线出现异常引起，如存储器校验错、总线错误等。
- **程序性异常**：也称软件中断，是指在CPU内部因执行指令而引起的异常事件。如整除0、溢出、断点、单步跟踪、非法指令、栈溢出、地址越界、缺页等。按异常发生原因和返回方式的不同，可分为：
    1. **故障（Fault）**：在引起故障的指令启动后、执行结束前被检测到的异常事件。如指令译码时“非法操作码”，取数据时“缺段”或“缺页”，执行整数除法指令时“除数为0”等。“缺段”“缺页”等经处理后可回到发生故障的指令继续执行；“非法操作码”“除数为0”等无法恢复，必须终止进程执行。
    2. **自陷（Trap）**：也称陷阱或陷入，是预先安排的“异常”事件。事先在程序中用特殊指令或设置特殊控制标志设“陷阱”，执行到被设置“陷阱”的指令时，CPU执行完自陷指令后，根据不同“陷阱”类型处理，然后返回到自陷指令的下一条指令执行（自陷指令是转移指令时，返回到转移目标指令执行）。x86机器中程序调试“断点设置”和单步跟踪通过陷阱机制实现，系统调用指令、条件自陷指令等都属于陷阱指令。故障异常和自陷异常属于程序性异常（软件中断）。
    3. **终止（Abort）**：执行指令过程中发生使计算机无法继续执行的硬件故障，如控制器出错、存储器校验错、总线错误等，程序无法继续执行，只能终止，调出异常服务程序来重启系统。这种异常不是由特定指令产生，而是随机发生的。终止异常和外中断属于硬件中断。

#### 中断的分类
中断是指来自CPU外部、与CPU执行指令无关的事件引起的中断，包括I/O设备发出的I/O中断（如键盘输入、打印机缺纸等），或发生某种特殊事件（如用户按Esc键、定时器计数时间到）等。外部I/O设备通过特定的中断请求信号线向CPU提出中断请求，CPU每执行完一条指令就检查中断请求信号线，若检测到中断请求，则进入中断响应周期。
中断可分为：
- **可屏蔽中断**：通过可屏蔽中断请求线INTR向CPU发出的中断请求。CPU可以通过在中断控制器中设置相应的屏蔽字来屏蔽它或不屏蔽它，被屏蔽的中断请求将不被送到CPU。
- **不可屏蔽中断**：通过专门的不可屏蔽中断请求线NMI向CPU发出的中断请求，通常是非常紧急的硬件故障，如电源掉电等。这类中断请求信号不可被屏蔽，让CPU快速处理紧急事件。

中断和异常的不同点：
1. “缺页”或“溢出”等异常事件是由特定指令在执行过程中产生的，而中断不和任何指令相关联，也不阻止任何指令的完成。
2. 异常的检测由CPU自身完成，不必通过外部的某个信号通知CPU。对于中断，CPU必须通过中断请求线获取中断源的信息，才能知道哪个设备发生了何种中断。

此外，根据识别中断服务程序地址的方式，可分为向量中断和非向量中断；根据中断处理过程是否允许被打断，还可分为单重中断和多重中断。 

### 异常和中断响应过程
当CPU执行指令时，若出现异常或中断请求，需进行相应处理。从CPU检测到异常或中断事件，到调用相应处理程序的过程，称为异常和中断响应。其响应过程主要包括以下三个方面：
1. **关中断**：在保存断点和程序状态期间，为防止新的中断干扰，需禁止响应新中断，即关中断。通常通过设置“中断允许”（IF）触发器来实现，当IF = 1时，为开中断，允许响应中断；当IF = 0时，为关中断，不允许响应中断。
2. **保存断点和程序状态**：为确保异常和中断处理后能正确返回被中断的程序继续执行，需将程序的断点（返回地址）保存到栈或特定寄存器中，一般保存在栈中，以支持异常或中断的嵌套。同时，被中断时的程序状态字寄存器PSW的内容也需保存到栈或特定寄存器中，在异常和中断返回时再恢复到PSW中。
3. **识别异常和中断并转到相应的处理程序**：
    - **软件识别方式**：CPU设置异常状态寄存器来记录异常原因。操作系统通过统一的异常或中断查询程序，按优先级顺序查询异常状态寄存器，检测异常和中断类型，先查询到的先处理，然后转到内核中相应的处理程序。
    - **硬件识别方式（向量中断）**：异常或中断处理程序的首地址称为中断向量，所有中断向量存放在中断向量表中。每个异常或中断都有指定的中断类型号，在中断向量表中，类型号与中断向量一一对应，可依据类型号快速找到对应的处理程序。

整个响应过程不可被打断。中断响应结束后，CPU从PC中取出对应中断服务程序的第一条指令开始执行，直至中断返回，该任务由CPU执行中断服务程序完成，整个中断处理过程由软、硬件协同实现。

## 指令流水线
先前介绍的指令在单周期处理机中以串行方式执行，同一时刻CPU中仅有一条指令在执行，导致各功能部件的使用率较低。现代计算机普遍采用指令流水线技术，使同一时刻有多条指令在CPU的不同功能部件中并发执行，显著提高了功能部件的并行性和程序的执行效率。

### 指令流水线的基本概念
提高处理机并行性的方法主要有两种：
1. **时间上的并行技术（流水线技术）**：将一个任务分解为多个不同的子阶段，每个子阶段在不同的功能部件上并行执行，以便在同一时刻能同时执行多个任务，从而提升系统性能。
2. **空间上的并行技术**：在处理机内设置多个执行相同任务的功能部件，并使这些功能部件并行工作，这类处理机被称为超标量处理机。

一条指令的执行过程可分解为若干阶段，每个阶段由相应的功能部件完成。若将各阶段视为流水段，则指令的执行过程便构成了一条指令流水线。假设一条指令的执行过程分为以下5个阶段：
1. **取指（IF）**：从指令存储器或Cache中获取指令。
2. **译码/读寄存器（ID）**：操作控制器对指令进行译码，同时从寄存器堆中读取操作数。
3. **执行/计算地址（EX）**：执行运算操作或计算地址。
4. **访存（MEM）**：对存储器进行读、写操作。
5. **写回（WB）**：将指令执行结果写回到寄存器堆。

将第$k + 1$条指令的取指阶段提前到第$k$条指令的译码阶段，使第$k + 1$条指令的译码阶段与第$k$条指令的执行阶段同时进行。理想情况下，每个时钟周期都有一条指令进入流水线，每个时钟周期都有一条指令完成，每条指令的时钟周期数（即CPI）均为1。

#### 利于实现指令流水线的指令集特征
为便于实现指令流水线，指令集应具备以下特征：
1. **指令长度尽量一致**：这样可简化取指令和指令译码操作，避免因取指令时间长短不一导致取指部件复杂，同时也有利于指令译码。
2. **指令格式尽量规整**：尽量保证源寄存器的位置相同，便于在指令未知时即可读取寄存器操作数，否则需译码后才能确定指令中各寄存器编号的位置。
3. **采用LOAD/STORE型指令**：规定其他指令不能访问存储器，可将LOAD/STORE指令的地址计算和运算指令的执行步骤规整在同一周期内，减少操作步骤。
4. **数据和指令在存储器中“按边界对齐”存放**：可减少访存次数，使所需数据在一个流水段内就能从存储器中获取。 

### 流水线的基本实现
#### 流水线设计的原则
在单周期实现中，并非所有指令都需经历完整的5个阶段，但单周期CPU的时钟频率由数据通路中的最长路径决定，即只能以执行速度最慢的指令作为设计其时钟周期的依据。

流水线设计的原则：
1. 指令流水段个数以最复杂指令所用的功能段个数为准。
2. 流水段的长度以最复杂的操作所花的时间为准。

假设某条指令的5个阶段所花时间分别为：取指$200ps$；译码$100ps$；执行$150ps$；访存$200ps$；写回$100ps$，该指令总执行时间为$750ps$。按照流水线设计原则，每个流水段长度为$200ps$，所以每条指令执行时间为$1ns$，比串行执行时增加了$250ps$。假设某程序有$N$条指令，单周期处理机所用时间为$N×750ps$，而流水线处理机所用时间为$(N + 4)×200ps$。由此可见，流水线方式不能缩短单条指令执行时间，但可大幅提高整个程序的执行效率。

#### 流水线的逻辑结构
每个流水段后面需增加一个流水段寄存器，用于锁存本段处理完的所有数据，确保本段执行结果能在下个时钟周期供下一流水段使用。各种寄存器和数据存储器均采用统一时钟$CLK$进行同步，每来一个时钟，各段处理完的数据都将锁存到段尾的流水段寄存器中，作为后段的输入，同时当前段也会接收前段通过流水段寄存器传递过来的数据。

一条指令会依次进入$IF$（取指）、$ID$（译码/读寄存器）、$EX$（执行/计算地址）、$MEM$（访存）、$WB$（写回）五个功能段进行处理。当第一条指令进入$WB$段后，各流水段都包含一条不同的指令，流水线中将同时存在$5$条不同的指令并行执行。

**注意**：在考试中，若没有明确说明，可不考虑流水寄存器的时延。

#### 流水线的时空图表示
通常用时空图直观描述流水线的执行情况。

在时空图中，横坐标表示时间，分割成长度相等的时间段$T$；纵坐标为空间，表示当前指令所处的功能部件。例如，第一条指令$I1$在时刻$0$进入流水线，在时刻$5T$流出流水线；第二条指令$I2$在时刻$T$进入流水线，在时刻$6T$流出流水线，以此类推，每隔一个时间$T$就有一条指令进入流水线，从时刻$5T$开始每隔一个时间$T$就有一条指令流出流水线。

从时空图中可看出，在时刻$10T$时，流水线上便有$6$条指令流出。若采用串行方式执行，在时刻$10T$时，只能执行$2$条指令，使用流水线方式可成倍提高计算机的速度。

只有大量连续任务不断输入流水线，才能充分发挥流水线的性能。指令的执行是连续不断的，非常适合采用流水线技术。对于其他部件级流水线，如浮点运算流水线，同样仅适合提升浮点运算密集型应用的性能，对于单个运算是无法提升性能的。 

### 流水线的冒险与处理
在指令流水线中，某些情况会使后续指令无法正确执行，进而导致流水线阻塞，这种现象被称为流水线冒险。根据冒险产生的原因，可分为**结构冒险**、**数据冒险**和**控制冒险**三种类型。不同类型指令在各流水段的操作存在差异，表5.2中列出了几类指令在各流水段中的操作。

#### 结构冒险
结构冒险是指不同指令在同一时刻争用同一功能部件而产生的冲突，也叫资源冲突，由硬件资源竞争引发。例如，指令和数据常存于同一存储器中，当第$i$条$LOAD$指令在第$4$个时钟周期进入$MEM$段时，第$i + 3$条指令的$IF$段也要访存取指令，此时就会出现访存冲突。为解决这一问题，可在前一条指令访存时，暂停（一个时钟周期）后一条指令的取指操作。若第$i$条指令不是$LOAD$指令，在$MEM$段不访存，则不会发生访存冲突。

解决结构冲突的方法有：
1. 前一指令访存时，让后一条相关指令（及其后续指令）暂停一个时钟周期。
2. 设置多个独立部件。如对于寄存器访问冲突，可将寄存器的读口和写口独立；对于访存冲突，单独设置数据存储器和指令存储器。现代$Cache$机制中，$L1$级$Cache$常采用数据$Cache$和指令$Cache$分离的方式，避免资源冲突。

#### 数据冒险
数据冒险也叫数据相关，产生原因是后面指令要用到前面指令的结果时，前面指令的结果尚未产生。在非乱序执行的流水线中，所有数据冒险都是由于前面指令写结果之前，后面指令就需要读取造成的，这种冒险被称为写后读（Read After Write，RAW）冲突。在按序执行的流水线中（统考中通常采用这种方式），仅可能出现$RAW$冲突。

例如：
```
I1 add R1,R2,R3  //(R2)+(R3)→R1
I2 Sub R4,R1,R5  //(R1)-(R5)→R4
```
在写后读（$RAW$）冲突中，指令$I2$的源操作数是指令$I1$的目的操作数。正常读/写顺序是指令$I1$先写入$R1$，再由指令$I2$读取$R1$。非流水线中，这种顺序自然维持；但在流水线中，由于重叠操作，读/写顺序关系发生变化。

解决$RAW$数据冲突的方法有：
1. **延迟执行相关指令**：把遇到数据相关的指令及其后续指令暂停一至几个时钟周期，直到数据相关问题解决后再继续执行。可通过软件插入空操作“$nop$”指令或硬件阻塞（$stall$）实现。由上述示例可见，在第$5$个时钟周期，$add$指令才将运算结果写入$R1$，但后继$sub$指令在第$3$个时钟周期就要从$R1$中读数，导致先写后读顺序变为先读后写，产生$RAW$数据冲突。若不处理，按原读/写顺序会导致结果错误。可暂停$sub$指令$3$个时钟周期，直至$add$指令结果生成。另外，对于$I1$和$I2$的数据相关问题，还可将寄存器的写口和读口分别控制在前、后半个时钟周期内操作，使前半周期写入$R1$的值在后半周期马上被读出，这样$I1$的$WB$段和$I2$的$ID$段可重叠执行，只需延迟$2$个时钟周期。
2. **采用转发（旁路）技术**：设置相关转发通路，前一条指令未将计算结果写回寄存器时，下一条指令也不从寄存器读，而是将数据通路中生成的中间数据直接转发到$ALU$的输入端。如指令$I1$在$EX$段结束时得到$R1$的新值，存于$EX/MEM$流水段寄存器中，可直接从该寄存器中取出数据返送到$ALU$输入端，使指令$I2$执行时$ALU$使用$R1$的新值。增加转发通路后，相邻两条运算类指令之间、相隔一条的两个运算类指令之间的数据相关带来的数据冒险问题可得到解决。
3. **$load-use$数据冒险的处理**：若$load$指令与其后紧邻的运算类指令存在数据相关问题，无法通过转发技术解决，这种情况称为$load-use$数据冒险。例如：
```
I2 load r2,12(r1)  //M[(r1)+12]→ (r2)
I3 add r4,r3, r2  //(r3)+(r2)→ (r4)
```
由表5.2可知，$load$指令在$MEM$段结束时才能得到主存中的结果，送$MEM/WB$流水段寄存器，在$WB$段的前半周期才能存入$R2$的新值，但随后的$add$指令在$EX$阶段就要取$R2$的值，得到的是旧值。对于$load-use$数据冒险，最简单的做法是由编译器在$add$指令之前插入一条$nop$指令，使$add$指令的$EX$段能从$MEM/WB$流水段寄存器中取出$load$指令的最新结果。最好的办法是在程序编译时进行优化，调整指令顺序以避免出现$load-use$现象。

#### 控制冒险
指令一般顺序执行，但遇到改变指令执行顺序的情况，如执行转移或返回指令、发生中断或异常时，会改变$PC$值，造成断流，这就是控制冲突。

对于由转移指令引起的冲突，最简单的处理方法是推迟后续指令的执行。通常把因流水线阻塞带来的延迟时钟周期数称为延迟损失时间片$C$。例如：
```
loop:add R1,R1,1  //(R1)+1→R1
I2 bne R1,R2, loop  //if(R1)!=(R2) goto loop
```
假设$R2$存放常数$N$，$R1$初值为$1$，$bne$指令在$EX$段通过计算设置条件码，并在$MEM$段确定是否将$PC$值更新为转移目的地址，所以仅当$bne$指令执行到第$5$个时钟结束时才能将转移目标地址送$PC$。为解决此问题，在数据通路检测到分支指令后，可在分支指令后插入$C$（此处$C = 3$）条$nop$指令。

解决控制冲突的方法有：
1. 对于由转移指令引起的冲突，可采用和解决数据冲突相同的软件插入“$nop$”指令和硬件阻塞（$stall$）的方法，即延迟损失多少时间片，就插入多少条$nop$指令。
2. 对转移指令进行分支预测，尽早生成转移目标地址。分支预测分为简单（静态）预测和动态预测。若静态预测的条件总是不满足，则按序继续执行分支指令的后续指令。动态预测根据程序转移的历史情况进行动态预测调整，有较高的预测准确率。

**注意**：$Cache$缺失的处理过程也会引起流水线阻塞。 

### 流水线的性能指标
#### 流水线的吞吐率
流水线的吞吐率指单位时间内流水线完成的任务数量或输出结果的数量。
其最基本公式为：$TP = \frac{n}{T_{k}}$，其中$n$是任务数，$T_{k}$是处理完$n$个任务所用的总时间。设$k$为流水段的段数，$\Delta t$为时钟周期。在输入流水线的任务连续的理想情况下，一条$k$段流水线能在$k + n - 1$个时钟周期内完成$n$个任务，则此时流水线的吞吐率为：$TP = \frac{n}{(k + n - 1)\Delta t}$。当连续输入的任务数$n \to \infty$时，可得到最大吞吐率为$TP_{max} = \frac{1}{\Delta t}$。

#### 流水线的加速比
完成同样一批任务，不使用流水线与使用流水线所用的时间之比。
其基本公式为：$S = \frac{T_{0}}{T_{k}}$，其中$T_{0}$表示不使用流水线的总时间，$T_{k}$表示使用流水线的总时间。一条$k$段流水线完成$n$个任务所需的时间为$T_{k} = (k + n - 1)\Delta t$，顺序执行$n$个任务时，所需的总时间为$T_{0} = kn\Delta t$。将$T_{0}$和$T_{k}$值代入上式，可得流水线的加速比为：$S = \frac{kn\Delta t}{(k + n - 1)\Delta t} = \frac{kn}{k + n - 1}$。当连续输入的任务数$n \to \infty$时，可得最大加速比为$S_{max} = k$。

### 高级流水线技术
增加指令级并行的策略有两种：一是多发射技术，采用多个内部功能部件，使流水线功能段能同时处理多条指令，处理机一次可发射多条指令进入流水线执行；二是超流水线技术，通过增加流水线级数让更多指令同时在流水线中重叠执行。
#### 超标量流水线技术
也叫动态多发射技术，每个时钟周期内可并发多条独立指令，以并行操作方式将两条或多条指令编译并执行，需配置多个功能部件。在简单的超标量CPU中，指令按顺序发射执行。为提高并行性能，多数超标量CPU结合动态流水线调度技术，通过动态分支预测等手段，指令可不按顺序执行，即乱序执行。
#### 超长指令字技术
也叫静态多发射技术，由编译程序挖掘指令间潜在的并行性，将多条能并行操作的指令组合成一条具有多个操作码字段的超长指令字（可达几百位），需采用多个处理部件。
#### 超流水线技术
流水线功能段划分越多，时钟周期越短，指令吞吐率越高，超流水线技术通过提高流水线主频提升性能。但流水线级数越多，流水寄存器开销越大，流水线级数有限制。

超流水线CPU在流水线充满后，每个时钟周期执行一条指令，$CPI = 1$，但主频更高；多发射流水线CPU每个时钟周期可处理多条指令，$CPI < 1$，不过成本更高、控制更复杂。 

## 多处理器的基本概念

### SISD、SIMD、MIMD的基本概念
基于指令流和数据流的数量，计算机体系结构分为SISD、SIMD、MISD和MIMD四类。常规单处理器属于SISD，常规多处理器属于MIMD。
1. **单指令流单数据流（SISD）结构**：传统串行计算机结构，通常含一个处理器和一个存储器，处理器一段时间内仅执行一条指令，按序串行执行指令。部分SISD计算机采用流水线方式，会设置多个功能部件，并用多模块交叉方式组织存储器，本书前面内容多属此结构。
2. **单指令流多数据流（SIMD）结构**：一个指令流同时处理多个数据流，即数据级并行技术。由一个指令控制部件和多个处理单元组成，各处理单元执行同一条指令，但有各自地址寄存器，处理不同数据。顺序应用程序编译后，可按SISD或SIMD组织运行。SIMD处理数组的for循环时效率高，如16对数据运算的指令在16个ALU中同时运算，一次即可完成；使用case或switch语句时效率低。
3. **多指令流单数据流（MISD）结构**：同时执行多条指令处理同一个数据，实际不存在此类计算机。
4. **多指令流多数据流（MIMD）结构**：同时执行多条指令处理多个不同数据，分为多计算机系统和多处理器系统。多计算机系统中每个节点有私有存储器和独立主存地址空间，通过消息传递传送数据；多处理器系统即共享存储多处理器（SMP）系统，有共享单一地址空间，通过存取指令访问所有存储器。向量处理器是SIMD的变体，可直接操作一维数组（向量），将数据放入向量寄存器流水化操作后写回结果，在数值模拟等领域提升性能。SIMD是数据级并行模式，MIMD是更高程度的线程级或以上并行计算模式。

### 硬件多线程的基本概念
传统CPU中线程切换开销大，影响系统性能，为减少开销产生硬件多线程。支持硬件多线程的CPU需为每个线程提供单独通用寄存器组、程序计数器等，切换时只需激活选中寄存器，减少与存储器数据交换环节。硬件多线程有3种实现方式：
1. **细粒度多线程**：多个线程轮流交叉执行指令，指令不相关可乱序并行，每个时钟周期可切换线程，如时钟周期$i$执行线程$A$指令，$i + 1$执行线程$B$指令。
2. **粗粒度多线程**：连续几个时钟周期执行同一线程指令序列，仅当前线程阻塞（如Cache缺失）时切换线程。切换时需清除被阻塞流水线，重载新线程指令，开销比细粒度多线程大。这两种多线程实现了指令级并行，线程级不并行。
3. **同时多线程**：同时多线程（SMT）是上述两种的变体，实现指令级和线程级并行，同一时钟周期发射不同线程的多条指令执行。Intel处理器的超线程（Hyper-threading）就是SMT，在单处理器或核中设两套线程状态部件，共享高速缓存和功能部件。

### 多核处理器的基本概念
多核处理器将多个处理单元集成到单个CPU中，每个单元为一个核（core），也称片上多处理器。每个核可自有Cache或共享，所有核通常共享主存储器。在多核计算机系统中，需采用多线程（或多进程）执行以发挥性能，使每个核同一时刻有线程执行。多核上的多线程是物理并行执行，单核上的多线程是交错执行，同一时刻只有一个线程执行。例如滚石头，串行处理器逐一滚动需4分钟，双核处理器两人各滚两颗需2分钟，向量处理器同时滚动四颗理论上只需1分钟。

### 共享内存多处理器的基本概念
具有共享单一物理地址空间的多处理器为共享内存多处理器（SMP），处理器通过共享变量通信，可访问存储器任何位置，且可在各自虚拟地址空间运行程序。单一地址空间的多处理器有两种类型：
1. **统一存储访问（UMA）多处理器**：每个处理器对所有存储单元访问时间大致相同，与处理器和访问字无关。
2. **非统一存储访问（NUMA）多处理器**：某些存储器访存速度因处理器和访问字而异，主存被分割分配给不同处理器。早期计算机内存控制器未集成进CPU，访存经北桥芯片，为UMA构架。后因CPU性能提升，多核、多CPU对前端总线争用致其成为瓶颈，NUMA构架诞生，内存控制器集成到CPU内，每个CPU有独立内存控制器和本地内存，CPU间通过QPI总线相连，可访问远程内存，NUMA架构下本地内存访问快于远程内存。

多个处理器可能同时访问同一共享变量，操作时需同步，常用加锁方式控制互斥访问，同一时刻只有一个处理器获锁，其他需等待解锁。UMA构架多处理器中，多核系统的Cache一致性包括Cache与内存、各CPU的Cache之间的一致性，即不同CPU的Cache对同一内存数据不应有不一致内容。 